---
title: "TimeSeries2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA)
library(knitr)
library(tidyverse)
library(aTSA)
```

# Work with git

```{terminal, eval=FALSE}
# sync with the latest version
# Everytime before you start working, please sync with the latest version first.
# run this two lines of code in terminal line by line (seperately)

git fetch upstream
git merge upstream/master

# Then please read the message which will be sent back
```

# Imported data

```{r}
dat = read.csv("B3_HWA2.csv", stringsAsFactors = FALSE)
```

```{r}
# we want 400, and leave 4 out for forecasting
datm <- dat[1:400, ] # subset 400 first rows of dat, include all columns
datf <- dat[401:404, ] # subset last 4 rows of dat, include all columns


# process 1-5
Y1 <- as.ts(datm[ , 3])
Y2 <- as.ts(datm[ , 4])
Y3 <- as.ts(datm[ , 5])
Y4 <- as.ts(datm[ , 6])
Y5 <- as.ts(datm[ , 7])

```


#Introduction

#Table of contents

## Task 1

### Y1
####Identification
In Graph 1, the time series *Y1* is plotted. By inspection, there does not seem to be any trend. The series seems to have a constant mean, somewhere around 0, and also the variance looks fairly constant. Hence, it seems like the two first requirements for covariance stationarity are fulfilled; a constant mean and variance.

++++Graph 1++++++

Some unit root processes do give rise to data that show no obvious trend, although the process indeed has a stochastic trend. In that case, the process is not covariance stationary, but rather *Difference Stationary*. Since we need the data to be covariance stationary in order to proceed to estimation of the model, we must know whether this particular realization is a result of a unit root process. By inspection, it does not look like a unit root process, since such a process has an infinite memory. Hence, in case of a unit root process, we would see little or no decline in the ACF.


Several different processes might give rise to the realization seen in the time series plot in Graph 1. To find out more we turn instead to the ACF, where we see three significant spikes, which are decreasing geometrically. Combine this with the looks of the PACF, which has two significant spikes, and one can make a qualified guess which underlying process is generating the data here. It could be an AR(2), since that kind of process indeed has a geometrically decreasing ACF and 2 significant PACF spikes. However, it could also be an ARMA(1,1), if one rather interpretates the PACF as geometrically decreasing. Hence, we have two potentially true models, which we have to evaluate:

AR(2): $Y_1=\phi_0+\phi_1Y_{t-1}+\phi_2Y_{t-2}+e_t$
ARMA(1,1) $Y_t=\phi_1Y_{t-1}+e_t-\theta_1e_{t-1}$

In both these cases, the error term $e_t$ is independently and identically distributed with mean 0 and a constant variance.


####Estimation and evaluation of AR(2)
All models is estimated using the maximum likelihood method.

When estimating the AR(2) model, it becomes:

AR(2): $Y_{1} = 0.0044-0.77Y_{t-1}-0.20Y_{t-2}+\hat{e}_t$


Where the values within paranthesis are the standard errors of the estimates, the Y:s are the observed value of Y in the indexed time period, and $\hat{e}_t$ is the residual. COMMENT ON INDIVIDUAL SIGNIFICANCE! To verify whether using this model is any good or not, we perform a *residual analysis*. If the estimated model has captured all systematic variation properly, the residuals must be uncorrelated and stationary.

Graph 2 shows the residuals plotted over time, as well as the residual ACF and PACF. When looking at the time series plot, the mean seems to be at 0 and the variance looks constant. In the graph of the ACF, there is one significant spike at k=0. However $\rho_0$ is by construction 1, which makes it unimportant to our analysis. Instead, we look at the spikes where k is equal to or bigger than 1, and we see that they are all nonsignificant. 

+++++Graph 2++++++++

Note that when evaluating a spike in relation to the blue dotted significance line in the graph, we essentially perform a Z-test of an individual autocorrelation. This might be problematic, since we expect every 20th test (*by construction* of a Z-test with significance level 5%) to show significance due to pure chance. To avoid this problem, one performs a *Ljung-Box Test*, which simultaneously tests whether one or several of the autocorrelations are nonzero. In this case, we get the p-value 0.693, which makes us accept the null that all autocorrelations are 0. Hence, all autocorrelations seem to be undistinguishable from 0 on a 5% significance level. Thus we conclude that the residuals of the AR(2) estimation are uncorrelated.

COMMENT ON NORMALITY!? QQ-plot:
+++++Graph 3++++++++

When comparing this model with the ARMA(1,1) (which we soon will evaluate), one can also look at the so called *Aikaike Information Criteria* (AIC). The AIC for this model is 1113.96. It does not say much on it's own, but below, it will be compared to the AIC of ARMA(1,1)



####Estimation and evaluation of ARMA(1,1)
The realization in Graph 1 could perhaps be coming from an ARMA(1,1) process instead. To test this, we first estimate the model to be:
ARMA(1,1) $$Y_t=0.0045-0.478Y_{t-1}-0.30e_{t-1}+ \hat{e}_{t}$$

COMMENT ON THE MODEL AND ON IT'S p-VALUES!

Graph 3 shows the residual analysis, id est an analysis over $\hat{e}_{t}$. It is remarkably similar to the one using AR(2), in Graph 2. When performing a Ljung-Box test, we get the p-value 0.657. Hence, all autocorrelations are indeed not significant different from 0. COMMENT ON NORMALITY! Consequently, by just studying the time series plots and the autocorrelations, we cannot decide which one of the two models (AR(2) or ARMA(1,1)) that is preferable.

++++Graph 4++++

When deciding which model is the best, one can also look at the so called AIC. The AIC for his model is 1113.98. The differences between the AIC-values in the two different models that weâ€™ve tried here is very small. However the AIC for the AR(2) model is somewhat smaller. Hence, we choose the AR(2) model to proceed with and to perform forecasts. 

++++Notes:+++++
Box.test(E11, lag = 20, type = c("Ljung-Box"), fitdf = 2)
qqnorm(E11)
Box.test(E1, lag = 20, type = c("Ljung-Box"), fitdf = 2)
qqnorm(E1)


####Forecasting
When making our forecasts, we are using the AR(2) model. Hence, all predictions of Y1 are made using: 

AR(2): $\hat{Y}_1=0.0044-0.77Y_{t-1}-0.20Y_{t-2}$

Graph 5 shows the predicted $\hat{Y}_t$ after t=400, together with a 95% prediction interval. The predicted values are very close to 0, and with 95% confidence, the true values are not bigger than around 1 and not smaller than around -1.

+++++Graph 5++++++

In Graph 6, we compare the predicted values with the actual, observed, observations. It becomes obvious that the absolute values of both $Y_401$, $Y_402$ and $Y_403$ are bigger than 1. Hence, by a first look, the prediction does not seem to be very good. However, the mean of the actual observations must be fairly close to the predicted line.

+++++Graph 6++++++

To evaluate a forecast, there are several measures. The *Mean Square Error* (MSE) gives higher weights to outliers. To get the measure on the right scale, one can square the Mean Square Error, and get the *Root Mean Square Error* (RMSE). Moreover, we will use the *Mean Absolute Percentage Error* (MAPE). Theses measures are presented in Table 1. Of course, we want the error measures to be as small as possible. As seen in Table 1, the MSE is ....., the RMSEA is 12 and MAPE is 108.







### Y2
####Identification
In Graph X, the time series *Y2* is plotted. By inspection, there does not seem to be any trend, and the mean and variance look fairly constant. Hence, it seems like the two first requirements for covariance stationarity are fulfilled; a constant mean and variance. Moreover, it does not look like a unit root process, since the ACF is declining. 
++++Graph 1++++++

Since several different processes might give rise to the realization seen in the time series plot, we also turn to the correlogram. The ACF has several individually significant spikes, and is geometrically decreasing. The PACF has only 1 significant spike. Consequently, we would guess that this is a realization of an AR(1) process. Hence, we have one model that we would like to estimate:

AR(2): $Y_1=\phi_0+\phi_1Y_{t-1}+e_t$

Where the error term $e_t$ is independently and identically distributed with mean 0 and a constant variance.
```{r}
## Y2 - AR(1)
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(Y2, main = "Time Series Y2") # time series plot
acf(Y2, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(Y2, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default
```

####Estimation and evaluation of MA(1)
All models is estimated using the maximum likelihood method.

When estimating the AR(1) model using the data from Y2, it becomes:

AR(2): $Y_1=0.0064-0.87Y_{t-1}+\hat{e}_t$


Where the Y:s are the observed value of Y in the indexed time period, and $\hat{e}_t$ is the residual. COMMENT ON INDIVIDUAL SIGNIFICANCE! To verify whether using this model is any good or not, we perform a residual analysis. If the estimated model has captured all systematic variation properly, the residuals must be uncorrelated and stationary.

Graph X shows the residuals plotted over time, as well as the residual ACF and PACF. When looking at the time series plot, the mean seems to be at 0 and the variance looks constant. The ACF and PACF only has nonsignificant spikes when tested individually. Moreover, the Ljung-Box Test generates a p-value 0.776, which makes us accept the null that all autocorrelations are 0. Hence, all autocorrelations seem to be undistinguishable from 0 on a 5% significance level. Thus we conclude that the residuals of the AR(2) estimation are uncorrelated.

COMMENT ON NORMALITY!? QQ-plot:

Since the residuals seem to be uncorrelated and stationary, the estimated model should be a good approximation of the underlying process.


####Forecasting
When making our forecasts, we are using an estimated AR(1) model. Hence, all predictions of Y2 are made using: 

AR(1): $\hat{Y}_1=0.0064-0.87Y_{t-1}$

Graph X shows the predicted $\hat{Y}_t$ after t=400, together with a 95% prediction interval. The predicted values are vary, from around 2 to -1. Moreover, for example at t=401, with 95% confidence, the true values are not bigger than around 3 and not smaller than around 1, etc.


In Graph X, we compare the predicted values with the actual, observed, observations. For t=401, t=402 and 403, the actual values do not seem to fall within the prediction interval. Only for t=404 it does. As seen in Table 1, MSE is 6.95, RMSE is 2.64 and MAPE is 403.



```{r}

## removing residuals from fitted model

### Y2
?arima
m2 <- arima(Y2, order = c(1, 0 , 0))
sigma22 <- m2$sigma2
E2 <- residuals(m2)
```


### Y3
####Identification
In Graph X, the time series *Y3* is plotted. By inspection, there is no obvious trend, and the mean and variance look fairly constant. Hence, it seems like the two first requirements for covariance stationarity are fulfilled; a constant mean and variance. Moreover, it does not look like a unit root process, since the ACF is declining. This is important to note since we cannot estimate a nonstationary process.


To find out exactly which underlying process we have, we also turn to the correlogram. The ACF has 2 individually significant spikes, and is decreasing. The PACF has more significant spikes, and is gemoetrically decreasing. Consequently, we would guess that this is a realization of an MA(2) process. Hence, we have one model that we would like to estimate:

MA(2): $Y_1=\theta_0+\theta_1e_{t-1}++\theta_2e_{t-2}+e_t$

Where $e_t$ is independently and identically distributed with mean 0 and a constant variance.


```{r}
## Y3 - MA(2)
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(Y3, main = "Time Series Y3") # time series plot
acf(Y3, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(Y3, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default
```

####Estimation and evaluation of MA(1)
All models is estimated using the maximum likelihood method.

When estimating the MA(1) model using the data from Y3, it becomes:

MA(2): $Y_1=0.014+0.52e_{t-1}-0.0096e_{t-2}+\hat{e}_t$


Where the Y:s are the observed value of Y in the indexed time period, and $\hat{e}_t$ is the residual. COMMENT ON INDIVIDUAL SIGNIFICANCE! To evaluate the estimation model, we perform a residual analysis. If the estimated model has captured all systematic variation properly, the residuals must be uncorrelated and stationary, as before.

Graph X shows the residuals plotted over time, as well as the residual ACF and PACF. When looking at the time series plot, the mean seems to be 0 and the variance looks constant. The ACF and PACF only has nonsignificant spikes when tested individually. Moreover, the Ljung-Box Test generates a p-value 0.771, which makes us accept the null. Hence, all autocorrelations seem to be undistinguishable from 0 on a 5% significance level. Thus we conclude that the residuals of the MA(2) estimation indeed are uncorrelated.

COMMENT ON NORMALITY!? QQ-plot:

Since the residuals seem to be uncorrelated and stationary, the estimated model should be a good approximation of the underlying process.

```{r}

## removing residuals from fitted model

### Y3
?arima
m3 <- arima(Y3, order = c(0, 0 , 2))
sigma23 <- m3$sigma2
E3 <- residuals(m3)
```


####Forecasting
When making our forecasts, we are using an estimated MA(2) model. Hence, all predictions of Y3 are made using: 

MA(2): $\hat{Y}_1=0.014+0.52e_{t-1}-0.0096e_{t-2}$

Graph X shows the predicted $\hat{Y}_t$ after t=400, together with a 95% prediction interval. The predicted values are all very close to 0, and with a with 95% confidence, the true values are not bigger than around 1 and not smaller than around -1. In Graph X, we compare the predicted values with the actual, observed, observations. We see that the predicted values systematically are higher than the actual ones. Moreover, a large share of the actual observations are outside the prediction interval. As seen in Table 1, MSE is 6.95, RMSE is 2.64 and MAPE is 403.


> #MSE
> (mean((y3-y3_hat)^2))
[1] 6.953121
> # RMSE
> sqrt(mean((y3-y3_hat)^2))
[1] 2.636877
> # MAPE
> mape <- 0
> for(i in 1:4) {
+   mape <- mape + abs((y3[i] - y3_hat[i])/y3[i])
+ }
> 100*mean(abs((y3-y3_hat)/y3))
[1] 402.8682

\newpage

### Y4

Here we are going to analyze the dataset Y4. As with the other datasets, we will use the Box-Jenkins approach.

#### Indentification

```{r} 
y_4 <- as.ts(datm[ , 6])

## y_4 - AR(2)
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(y_4, main = "Time Series y_4") # time series plot
acf(y_4, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(y_4, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default

```

Looking at our model, we can see that it looks centered around zero. It  looks fairly consistent in mean and variance. The ACF seems to be declining in a geometric fashion. The PACF has two "fingers". This leads us to suspect this is a AR-process of the second order, or AR(2).

#### Estimation

```{r}
### y_4
(m4 <- arima(y_4, order = c(2,0,0)))
sigma24 <- m4$sigma2
```


We estimate the parameters for the AR(2) process:

$$\phi_{1} = -0.282$$
$$\phi_{2} = 0.568$$
$$Var(\phi_{1}) = Var(\phi_{2}) = (0.041)^2$$
$$\sigma^2 = 0.9271$$

So our model is $$Y_{4} = 0.0174-0,282Y_{t-1} + 0.568Y_{t-2} + e_t$$

#### Evaluation

We begin by extracting the residuals. When we have done this we plot the residuals to check if the model has managed to capture the systematic variation.


```{r}
E4 <- residuals(m4)
```

```{r}
## y_4
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(E4, ylab = "Residuals", col = "blue", main = "Residuals from Fitted Model y_4")
abline(a = mean(E4), b = 0) # adds horizonta2l line with mean(E4) as intercept and 0 slope
abline(a = mean(E4) + sigma24, b = 0, lty="dotted") # same as above + sigma2
abline(a = mean(E4) - sigma24, b = 0, lty="dotted") # same as above - sigma2

acf(E4, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(E4, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default

```

The plot of the residuals looks like white noise, with no pattern or trend. Both the ACF and PACF are equal to zero, which they should be since the residuals are randomness. Does, it seems like we have managed to separate the systematic and random variation.

```{r}
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(y_4, E4, ylab = "Residuals", col = c("red","black"), main = "Residuals from Fitted Model y_4")
abline(a = mean(E4), b = 0) # adds horizonta2l line with mean(E4) as intercept and 0 slope
abline(a = mean(E4) + sigma24, b = 0, lty="dotted") # same as above + sigma2
abline(a = mean(E4) - sigma24, b = 0, lty="dotted") # same as above - sigma2
```

Here we can see the plot of y_4 in red, with the plot for the residuals superimposed on top, in black. We can see that the residuals do share all their patterns and trends with the plot for y_4.

```{r}
qqnorm(E4)
```

The QQ-plot looks to follow the theoretical values fairly well.

```{r}
(e4_acf <- acf(E4, lag.max = 20, type = "correlation", plot = F)) 
```

These are the autocorrelations for y_4, lag 0-20.

```{r}
Box.test(E4, type="Ljung-Box")
```

The p-value of the Box-Ljung test is 0.9317 > 0.05. Thus we can assume that not all autocorrelations are equal to zero for model y_4.

#### Forecast

```{r}
(y_4_pred <- predict(object = m4, n.ahead = 4))
```

Here are the the 401-404:th forecasted values for y_4. The values seem to oscillate between positive and negative values. The second row of values are the predicted standard errors.

```{r}
# we can submit more than one time series to the ts.plot() function. In this case
# i add, apart from  predicted y, predicty y +- se of prediction
ts.plot(y_4_pred$pred, y_4_pred$pred + y_4_pred$se, 
        y_4_pred$pred - y_4_pred$se, ylab = "Predicted Y", 
        main = expression(paste("Predicted ", Y['1'])), # we can use mathematical notation in r plots!
        lty=c(1:3),
        col = c("blue", "black", "black"))

```

Here we see a graphical plot of the predicted values, combined with the predicted values plus the standard error and minus the standard error. Here we can also see that they seem to "jump", between roughly 0.5 and -1.5.

```{r}
# compare fitted and actual
ts.plot(datf$Y4, y_4_pred$pred, col = c("red", "blue"))
# x & y need to be adjusted manually. A good idea is to take min(x) and add 1 as x - coordinate
# and max y remove 1 as y coordinate. Then fine tune 
legend(x = 401, y = 0.5, legend = c("actual", "fitted"), col = c("red", "blue"), lty=c(1,1))

```

These two plots combine the fitted plot with the actual plot. As we can see, they dont match up very well. There must be something that we have failed to capture - the predicted plot doesn't match the actual plot very well. The actual plot doesnt oscillate in the same way that the fitted model does. The actual data seem to start declining at time point 402, and start to recover by time point 403.

```{r}
### need some measurements of the forecast
y4 <- as.vector(datf$Y4) # no real need for these to be time series objects...
y4_hat <- as.vector(y_4_pred$pred) # ... so just store them as your plain vanilla vectors :)

# RMSEA
sqrt(mean((y4-y4_hat)^2))
# MAE 
mean(abs(y4-y4_hat))
# MAPE, not exactly sure whether n = 4 or 404 in the calculations
mape <- 0
for(i in 1:4) {
  mape <- mape + abs((y4[i] - y4_hat[i])/y4[i])
}
100*mean(abs((y4-y4_hat)/y4))
```

From model X, we can see that our MAPE (Mean Absolute Percentage Error) is very high, meaning that according to it we have a high amount of error. This strengthens the suspicion that we might have missed something.

### Y5

Here we are going to analyze the dataset Y5. As with the other datasets, we will use the Box-Jenkins approach.

#### Indentification

```{r}
Y5 <- as.ts(datm[ , 7])

## Y5 - AR(1,1)?
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(Y5, main = "Time Series Y5") # time series plot
acf(Y5, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(Y5, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default

```

This plot is rather choppy, but seems to be somewhat centered around zero. Its ACF seems to geometrically decline. The PACF seems to have a finger, but also seems to decline. It might be an ARMA, since both ACF and PACF seem to decline. If it is an ARMA, then its AR component is probably AR(2). Its MA component looks like an MA(2), since it has 3 "fingers" above zero, although one looks very close to zero.

#### Estimation

```{r}
### Y5
m5 <- arima(Y5, order = c(2, 0 , 3))
sigma25 <- m5$sigma2

m5
```

$$\phi_{1} = 1.1854$$
$$\phi_{2} = 0.4455$$
$$\theta_{1} = -0.0729$$
$$\theta_{2} = -0.2049$$
$$\theta_{3} = 0.1176$$
$$\sigma^2 = 0.9271$$

So our model is $$Y_{5} = 0.0339+1.1854Y_{t-1} + 0.4455Y_{t-2} - 0.0729e_{t-1} - 0.2049e_{t-2} + 0.1176e_{t-3} + e_t$$

#### Evaluation
```{r}
## removing residuals from fitted model
E5 <- residuals(m5)

```

We remove the residuals from the rest of the model.

```{r}
## Y5
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(E5, ylab = "Residuals", col = "blue", main = "Residuals from Fitted Model Y5")
abline(a = mean(E5), b = 0) # adds horizontal line with mean(E5) as intercept and 0 slope
abline(a = mean(E5) + sigma25, b = 0, lty="dotted") # same as above + sigma2
abline(a = mean(E5) - sigma25, b = 0, lty="dotted") # same as above - sigma2

acf(E5, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF
acf(E5, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF
par(mfrow = c(1,1)) # set plot window to default

```

From the residuals we have extracted, we see no evidance against our assumptions regarding what kind of model we have. Both the ACF and PACF are zero, and the plot is centered around zero.

```{r}
layout(matrix(c(1, 1, 2,
                1, 1, 3), nrow=2, byrow=TRUE)) 
ts.plot(Y5, E5, ylab = "Residuals", col = c("red","black"), main = "Residuals from Fitted Model y_4")
abline(a = mean(E4), b = 0) # adds horizonta2l line with mean(E4) as intercept and 0 slope
abline(a = mean(E4) + sigma24, b = 0, lty="dotted") # same as above + sigma2
abline(a = mean(E4) - sigma24, b = 0, lty="dotted") # same as above - sigma2
```

We can see that the residuals share some things with Y5, but are not distributed in the same way. The residual plot doesnt have the same choppyness, and seem to be more centered around zero, as well as being spread across a smaller interval.

```{r}
qqnorm(E5)
```

The QQ-plot looks approximatly correct, due to the fact that most of the values seem to fall on the theoretical line.

```{r}
(e5_acf <- acf(E5, lag.max = 20, type = "correlation", plot = F))

Box.test(E5, lag = 20)
```

Here we have the correlations for Y5, lags 0-20, as well as a Box-Jenkins test. The results from the test indicate that not all correlations are effectivly zero.

#### Forecast

```{r}
(y_5_pred <- predict(object = m5, n.ahead = 4))

```

Here we see the predicted values for Y5 for the numbers 401-404, with Y5 originally ending at 400. The predicted values seem to start as negative values, at around -0.58, but seem to become less negative with each time point, as t=404 is -0.156. The predicted standard error seems to be very large in comparison with the predicted values.

```{r}
### Predicted Y5
ts.plot(y_5_pred$pred, y_5_pred$pred + y_5_pred$se, 
        y_5_pred$pred - y_5_pred$se, ylab = "Predicted Y", 
        main = expression(paste("Predicted ", Y['5'])), # we can use mathematical notation in r plots!
        lty=c(1:3),
        col = c("blue", "black", "black"))

```

Due to the large size of our standard errors, we end up with a rather large interval. This in turn increases uncertainty. Our interval does not seem to follow our predicted values entirely either, as we can see that they increase faster before time point 402.

```{r}
# compare fitted and actual
ts.plot(datf$Y5, y_5_pred$pred, col = c("red", "blue"))
# x & y need to be adjusted manually. A good idea is to take min(x) and add 1 as x - coordinate
# and max y remove 1 as y coordinate. Then fine tune 
legend(x = 400.9, y = 0.1, legend = c("actual", "fitted"), col = c("red", "blue"), lty=c(1,1))


```

From the above plot we can conclude that our prediction of t =401-404 does not estimate the actual values of the series Y5. The actual plot seems to go in the same direction as the predicted data until it hits time point 402, after which it keeps declining. We saw a similar trend in Y4. 

```{r}
### need some measurements of the forecast
y5 <- as.vector(datf$Y5) # no real need for these to be time series objects...
y5_hat <- as.vector(y_5_pred$pred) # ... so just store them as your plain vanilla vectors :)

# RMSEA
sqrt(mean((y5-y5_hat)^2))
# MAE 
mean(abs(y5-y5_hat))
# MAPE, not exactly sure whether n = 4 or 404 in the calculations
mape <- 0
for(i in 1:4) {
  mape <- mape + abs((y5[i] - y5_hat[i])/y5[i])
}
100*mean(abs((y5-y5_hat)/y5))
```

# Task 2

## Import dataset

We download the dataset containing quarterly bilateral exchange rate between EU and other currency.

```{r}
dat = read.table(file = "ert_bil_eur_q.tsv", sep = '\t', header = TRUE)
kable(dat[65:70, 1:5], caption = "Quarterly bilateral exchange rate", digits = 2)
```

And then we only use the quarterly bilateral exchange rate between EU and SEK.

```{r}
dat = dat %>% 
  filter(statinfo.unit.currency.time == "END,NAC,SEK") %>% 
  select(-statinfo.unit.currency.time)
kable(dat[,1:9], caption = "Quarterly bilateral exchange rate between EU and SEK (Head 9)", digits = 2)
dat = t(dat)
y = dat[,1]
y = as.numeric(y)
y = y[!is.na(y)]
y = rev(y)
```

We "save" 5 observations for forecast evaluation.

```{r}
y_m = y[1:175]
y_f = y[176:181]
```

The first step that is to determine what type of process that generated my observed 190 observations.

## Identify the model

```{r}
# split up plot window
layout(matrix(c(1, 1, 2,
1, 1, 3), nrow=2, byrow=TRUE))
ts.plot(y_m, main = "Time Series") # time series plot, plot 1 in matrix argument
acf(y_m, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF, plot 2 in matrix argument
acf(y_m, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF, plot 3 in matrix argument
```

Then we perform a test to detect if there is a unit root in the process or not, which is the Augmented Dickey-Fuller (ADF) (unit root) test.

```{r}
adf.test(y_m)
```

According to the outcome of the test, we **can not reject** the null hypothesis that of a unit root in the series under the significance level 0.05 since all the p values are larger than $\alpha$.

To get discarded of the unit root we take the second difference of the time series. 

```{r}
y_m
y_m_dif = diff(y_m)
```

```{r}
layout(matrix(c(1, 1, 2,
1, 1, 3), nrow=2, byrow=TRUE))
ts.plot(y_m_dif, main = "Time Series") # time series plot, plot 1 in matrix argument
acf(y_m_dif, lag.max = 20, type = "correlation", plot = T, main = "ACF") # ACF, plot 2 in matrix argument
acf(y_m_dif, lag.max = 20, type = "partial", plot = T, main = "PACF") # PCAF, plot 3 in matrix argument
```

## Estimate the model



## Do the diagnostics

```{r}
Box.test(y_m_dif, lag = 4)
```

To do the diagnostics, we perform a test that there is no correlation between the lags of the model, we which is a Ljung-Box test where the null hypothesis is that we have zero correlation between the residuals and the alternative hypothesis is that there is a correlation between the residuals. The observed p-value is far larger than $\alpha$ which implies that we cannot reject the null hypothesis and conclude that our model has **no autocorrelation** in its time lags under the significance level 0.05. The result from the Ljung-box test is 

## Forecast


#Conclusions

#Appendix
